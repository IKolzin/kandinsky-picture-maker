{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNc7c6amMTxmZ7X5cCkABht",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IKolzin/kandinsky-picture-maker/blob/main/Picture_maker_(Kandinsky_2_1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVEMjlH3qMAg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@title Initialization - run this cell to install dependencies and prepare the model (usually takes several minutes) { display-mode: \"form\" }\n",
        "\n",
        "from PIL import Image\n",
        "import math\n",
        "def image_grid(images, max_columns = 5):\n",
        "    if len(images) == 0:\n",
        "      return\n",
        "    width, height = images[0].size\n",
        "    columns = min(len(images), max_columns)\n",
        "    rows = math.ceil(len(images) / max_columns)\n",
        "    grid = Image.new('RGB', size=(columns*width, rows*height))\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        grid.paste(img, box=(i%columns*width, i//columns*height))\n",
        "    return grid\n",
        "\n",
        "def install_kandinsky():\n",
        "    !pip install \"git+https://github.com/ai-forever/Kandinsky-2.git\"\n",
        "    !pip install git+https://github.com/openai/CLIP.git\n",
        "    from kandinsky2 import get_kandinsky2\n",
        "    model = get_kandinsky2('cuda', task_type='text2img', model_version='2.1', use_flash_attention=False)\n",
        "    return model\n",
        "\n",
        "def run_model(prompt=\"a cute and adorable kitten wearing a hat\",\n",
        "              batch_size=1, \n",
        "              num_steps=50,\n",
        "              guidance_scale=4,\n",
        "              prior_cf_scale=4,\n",
        "              prior_steps=5):\n",
        "    print(f'''Running with prompt: {prompt}\n",
        "    batch_size: {batch_size}, num_steps={num_steps} guidance_scale={guidance_scale}, prior_cf_scale={prior_cf_scale}, prior_steps={prior_steps}''')\n",
        "    images = model.generate_text2img(\n",
        "        prompt, \n",
        "        num_steps=num_steps,\n",
        "        batch_size=batch_size, \n",
        "        guidance_scale=guidance_scale,\n",
        "        h=768, w=768,\n",
        "        sampler='p_sampler', \n",
        "        prior_cf_scale=prior_cf_scale,\n",
        "        prior_steps=str(prior_steps)\n",
        "    )\n",
        "    return images\n",
        "\n",
        "model = install_kandinsky()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Text2Image - run this cell to get your pictures { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Type what you want to see\n",
        "prompt = 'an adorable kitten wearing a hat' #@param {type:\"string\"}\n",
        "#@markdown Or paste a python list with multiple prompts here (overrides the first field)\n",
        "prompts = [] #@param {type:\"raw\"}\n",
        "#@markdown If the notebook runs out of GPU memory, try reducing batch size (and restarting)\n",
        "batch_size = 2 #@param {type:\"slider\", min:1, max:3, step:1}\n",
        "#@markdown More batches directly leads to longer runtime\n",
        "num_batches = 1 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "#@markdown More steps take more time but in theory provide better quality\n",
        "num_steps = 40 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "#@markdown For Kandinsky, these paremeters don't seem to do much\n",
        "guidance_scale = 4 #@param {type:\"slider\", min:0.1, max:10, step:0.1}\n",
        "prior_cf_scale = 4 #@param {type:\"slider\", min:0.1, max:10, step:0.1}\n",
        "prior_steps = 4 #@param {type:\"slider\", min:2, max:10, step:1}\n",
        "\n",
        "result = []\n",
        "iterable = range(num_batches)\n",
        "if (not isinstance(prompts, list)) or (len(prompts) == 0):\n",
        "    _prompts = [prompt] * num_batches\n",
        "else:\n",
        "    _prompts = prompts * num_batches\n",
        "\n",
        "for prompt in _prompts:\n",
        "    result.extend(run_model(\n",
        "        prompt=prompt, num_steps=num_steps, batch_size=batch_size,\n",
        "        guidance_scale=guidance_scale, prior_cf_scale=prior_cf_scale, \n",
        "        prior_steps=prior_steps))\n",
        "\n",
        "image_grid(result)"
      ],
      "metadata": {
        "id": "3G7gKiMZtaEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to display individual images { display-mode: \"form\" }\n",
        "for img in result:\n",
        "    img.show()"
      ],
      "metadata": {
        "id": "tlcBYjx72lST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}